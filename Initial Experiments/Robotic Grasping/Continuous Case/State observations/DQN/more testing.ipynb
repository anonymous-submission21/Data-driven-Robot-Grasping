{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a8dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9d269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=C:\\Users\\Kami\\anaconda3\\envs\\robot_grasping\\lib\\site-packages\\pybullet_envs\\bullet\n"
     ]
    }
   ],
   "source": [
    "from pybullet_envs.bullet.kukaGymEnv import KukaGymEnv\n",
    "import random\n",
    "import os\n",
    "from gym import spaces\n",
    "import time\n",
    "import pybullet as p\n",
    "from pybullet_envs.bullet import kuka\n",
    "import numpy as np\n",
    "import pybullet_data\n",
    "import pdb\n",
    "import distutils.dir_util\n",
    "import glob\n",
    "from pkg_resources import parse_version\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc3477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KukaDiverseObjectEnv(KukaGymEnv):\n",
    "    def __init__(self,\n",
    "                urdfRoot=pybullet_data.getDataPath(),\n",
    "                actionRepeat=80,\n",
    "                isEnableSelfCollision=True,\n",
    "                renders=False,\n",
    "                isDiscrete=False,\n",
    "                maxSteps=8,\n",
    "                dv=0.06,\n",
    "                removeHeightHack=False,\n",
    "                blockRandom=0.3,\n",
    "                cameraRandom=0,\n",
    "                width=48,\n",
    "                height=48,\n",
    "                numObjects=5,\n",
    "                isTest=False,\n",
    "                from_pixels=False):\n",
    "        \n",
    "        self._isDiscrete = isDiscrete\n",
    "        self._timeStep = 1. / 240.\n",
    "        self._urdfRoot = urdfRoot\n",
    "        self._actionRepeat = actionRepeat\n",
    "        self._isEnableSelfCollision = isEnableSelfCollision\n",
    "        self._observation = []\n",
    "        self._envStepCounter = 0\n",
    "        self._renders = renders\n",
    "        self._maxSteps = maxSteps\n",
    "        self.terminated = 0\n",
    "        self._cam_dist = 1.3\n",
    "        self._cam_yaw = 180\n",
    "        self._cam_pitch = -40\n",
    "        self._dv = dv\n",
    "        self._p = p\n",
    "        self._removeHeightHack = removeHeightHack\n",
    "        self._blockRandom = blockRandom\n",
    "        self._cameraRandom = cameraRandom\n",
    "        self._width = width\n",
    "        self._height = height\n",
    "        self._numObjects = numObjects\n",
    "        self._isTest = isTest\n",
    "        \n",
    "        self._from_pixels = from_pixels\n",
    "        \n",
    "        \n",
    "        if self._renders:\n",
    "            self.cid = p.connect(p.SHARED_MEMORY)\n",
    "            if (self.cid < 0):\n",
    "                self.cid = p.connect(p.GUI)\n",
    "            p.resetDebugVisualizerCamera(1.3, 180, -41, [0.52, -0.2, -0.33])\n",
    "        \n",
    "        else:\n",
    "            self.cid = p.connect(p.DIRECT)\n",
    "        self.seed()\n",
    "        \n",
    "        if (self._isDiscrete):\n",
    "            if self._removeHeightHack:\n",
    "                self.action_space = spaces.Discrete(9)\n",
    "            else:\n",
    "                self.action_space = spaces.Discrete(7)\n",
    "        else:\n",
    "            self.action_space = spaces.Box(low=-1, high=1, shape=(3,)) # dx, dy, da\n",
    "            if self._removeHeightHack:\n",
    "                self.action_space = spaces.Box(low=-1, high=1, shape=(4,))  # dx, dy, dz, da\n",
    "                \n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(self._height,\n",
    "                                                                self._width,\n",
    "                                                                3))\n",
    "        self.viewer = None\n",
    "    \n",
    "    def reset(self):\n",
    "        look = [0.23, 0.2, 0.54]\n",
    "        distance = 1.\n",
    "        pitch = -56 + self._cameraRandom * np.random.uniform(-3, 3)\n",
    "        yaw = 245 + self._cameraRandom * np.random.uniform(-3, 3)\n",
    "        roll = 0\n",
    "        self._view_matrix = p.computeViewMatrixFromYawPitchRoll(look, distance, yaw, pitch, roll, 2)\n",
    "        fov = 20. + self._cameraRandom * np.random.uniform(-2, 2)\n",
    "        aspect = self._width / self._height\n",
    "        near = 0.01\n",
    "        far = 10\n",
    "        self._proj_matrix = p.computeProjectionMatrixFOV(fov, aspect, near, far)\n",
    "\n",
    "        self._attempted_grasp = False\n",
    "        self._env_step = 0\n",
    "        self.terminated = 0\n",
    "\n",
    "        p.resetSimulation()\n",
    "        p.setPhysicsEngineParameter(numSolverIterations=150)\n",
    "        p.setTimeStep(self._timeStep)\n",
    "        p.loadURDF(os.path.join(self._urdfRoot, \"plane.urdf\"), [0, 0, -1])\n",
    "\n",
    "        p.loadURDF(os.path.join(self._urdfRoot, \"table/table.urdf\"), 0.5000000, 0.00000, -.820000,\n",
    "                   0.000000, 0.000000, 0.0, 1.0)\n",
    "\n",
    "        p.setGravity(0, 0, -10)\n",
    "        self._kuka = kuka.Kuka(urdfRootPath=self._urdfRoot, timeStep=self._timeStep)\n",
    "        self._envStepCounter = 0\n",
    "        p.stepSimulation()\n",
    "        \n",
    "        urdfList = self._get_random_object(self._numObjects, self._isTest)\n",
    "        self._objectUids = self._randomly_place_objects(urdfList)\n",
    "        self._observation = self._get_observation()\n",
    "        return np.array(self._observation)\n",
    "\n",
    "    def _randomly_place_objects(self, urdfList):\n",
    "        objectUids = []\n",
    "        for urdf_name in urdfList:\n",
    "            xpos = 0.4 + self._blockRandom * random.random()\n",
    "            ypos = self._blockRandom * (random.random() - .5)\n",
    "            angle = np.pi / 2 + self._blockRandom * np.pi * random.random()\n",
    "            orn = p.getQuaternionFromEuler([0, 0, angle])\n",
    "            urdf_path = os.path.join(self._urdfRoot, urdf_name)\n",
    "            uid = p.loadURDF(urdf_path, [xpos, ypos, .15], [orn[0], orn[1], orn[2], orn[3]])\n",
    "            objectUids.append(uid)\n",
    "            \n",
    "            for _ in range(500):\n",
    "                p.stepSimulation()\n",
    "        return objectUids\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        if self._from_pixels:\n",
    "#             obs = super()._get_observation()\n",
    "            img_arr = p.getCameraImage(width=self._width,\n",
    "                                      height=self._height,\n",
    "                                      viewMatrix=self._view_matrix,\n",
    "                                      projectionMatrix=self._proj_matrix)\n",
    "            rgb = img_arr[2]\n",
    "            np_img_arr = np.reshape(rgb, (self._height, self._width,4))\n",
    "            o = np_img_arr[:, :, :3]\n",
    "            return o.transpose(2,0,1)\n",
    "        else:\n",
    "            o = self._kuka.endEffectorPos + [self._kuka.endEffectorAngle]\n",
    "            for uid in self._objectUids:\n",
    "                pos, quaternion = self._p.getBasePositionAndOrientation(uid)\n",
    "                o += list(pos)\n",
    "                o += list(quaternion)\n",
    "            return np.array(o)\n",
    "    \n",
    "    def step(self, action):\n",
    "        dv = self._dv\n",
    "        if self._isDiscrete:\n",
    "            assert isinstance(action, int)\n",
    "            if self._removeHeightHack:\n",
    "                dx = [0, -dv, dv, 0, 0, 0, 0, 0, 0][action]\n",
    "                dy = [0, 0, 0, -dv, dv, 0, 0, 0, 0][action]\n",
    "                dz = [0, 0, 0, 0, 0, -dv, dv, 0, 0][action]\n",
    "                da = [0, 0, 0, 0, 0, 0, 0, -0.25, 0.25][action]\n",
    "            else:\n",
    "                dx = [0, -dv, dv, 0, 0, 0, 0][action]\n",
    "                dy = [0, 0, 0, -dv, dv, 0, 0][action]\n",
    "                dz = -dv\n",
    "                da = [0, 0, 0, 0, 0, -0.25, 0.25][action]\n",
    "        else:\n",
    "            dx = dv * action[0]\n",
    "            dy = dv * action[1]\n",
    "            if self._removeHeightHack:\n",
    "                dz = dv * action[2]\n",
    "                da = 0.25 * action[3]\n",
    "            else:\n",
    "                dz = -dv\n",
    "                da = 0.25 * action[2]\n",
    "        \n",
    "        return self._step_continuous([dx, dy, dz, da, 0.3])\n",
    "    \n",
    "    def _step_continuous(self, action):\n",
    "        self._env_step += 1\n",
    "        self._kuka.applyAction(action)\n",
    "        for _ in range(self._actionRepeat):\n",
    "            p.stepSimulation()\n",
    "            if self._renders:\n",
    "                time.sleep(self._timeStep)\n",
    "            if self._termination():\n",
    "                break\n",
    "                \n",
    "        state = p.getLinkState(self._kuka.kukaUid, self._kuka.kukaEndEffectorIndex)\n",
    "        end_effector_pos = state[0]\n",
    "        if end_effector_pos[2] <= 0.1:\n",
    "            finger_angle = 0.3\n",
    "            for _ in range(500):\n",
    "                grasp_action = [0, 0, 0, 0, finger_angle]\n",
    "                self._kuka.applyAction(grasp_action)\n",
    "                p.stepSimulation()\n",
    "                finger_angle -= 0.3 / 100.\n",
    "                if finger_angle < 0:\n",
    "                    finger_angle = 0\n",
    "            for _ in range(500):\n",
    "                grasp_action = [0, 0, 0.001, 0, finger_angle]\n",
    "                self._kuka.applyAction(grasp_action)\n",
    "                p.stepSimulation()\n",
    "                if self._renders:\n",
    "                    time.sleep(self._timeStep)\n",
    "                finger_angle -= 0.3 / 100.\n",
    "                if finger_angle < 0:\n",
    "                    finger_angle = 0\n",
    "            self._attempted_grasp = True\n",
    "        observation = self._get_observation()\n",
    "        done = self._termination()\n",
    "        reward = self._reward()\n",
    "\n",
    "        debug = {'grasp_success': self._graspSuccess}\n",
    "        return observation, reward, done, debug\n",
    "    \n",
    "    def _reward(self):\n",
    "        reward = 0\n",
    "        self._graspSuccess = 0\n",
    "        for uid in self._objectUids:\n",
    "            pos, _ = p.getBasePositionAndOrientation(uid)\n",
    "            if pos[2] > 0.2:\n",
    "                self._graspSuccess += 1\n",
    "                reward = 1\n",
    "                break\n",
    "        return reward\n",
    "    \n",
    "    def _termination(self):\n",
    "        return self._attempted_grasp or self._env_step >= self._maxSteps\n",
    "    \n",
    "    def _get_random_object(self, num_objects, test):\n",
    "        if test:\n",
    "            urdf_pattern = os.path.join(self._urdfRoot, 'random_urdfs/*0/*.urdf')\n",
    "        else:\n",
    "            urdf_pattern = os.path.join(self._urdfRoot, 'random_urdfs/*[1-9]/*.urdf')\n",
    "        found_object_directories = glob.glob(urdf_pattern)\n",
    "        total_num_objects = len(found_object_directories)\n",
    "        selected_objects = np.random.choice(np.arange(total_num_objects), num_objects)\n",
    "        selected_objects_filenames = []\n",
    "        for object_index in selected_objects:\n",
    "            selected_objects_filenames += [found_object_directories[object_index]]\n",
    "        return selected_objects_filenames\n",
    "    \n",
    "    if parse_version(gym.__version__) < parse_version('0.9.6'):\n",
    "        _reset = reset\n",
    "        _step = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d44ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = KukaDiverseObjectEnv(renders=False,\n",
    "                           width=64,\n",
    "                           height=64,\n",
    "                           numObjects=1,\n",
    "                           maxSteps=15,\n",
    "                           from_pixels=False,\n",
    "                           isDiscrete=True\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3636a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU IS AVAILABLE :D\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU IS AVAILABLE :D') \n",
    "else:  \n",
    "    device = torch.device(\"cpu\") \n",
    "    print('GPU not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fdb4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                       ('state',\n",
    "                       'action',\n",
    "                       'next_state',\n",
    "                       'reward'))\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "        \n",
    "    def push(self, *args):\n",
    "        \"save a transition\"\n",
    "        self.memory.append(Transition(*args))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b39cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(11, 256) \n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 7)\n",
    "        \n",
    "    def forward(self, s): # s is the observation, a is the action \n",
    "        s = s.to(device)        \n",
    "\n",
    "        s = F.relu(self.fc1(s))\n",
    "        s = F.relu(self.fc2(s))\n",
    "        s = F.relu(self.fc3(s))\n",
    "        \n",
    "        return self.fc4(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79fbd393",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "GAMMA = 0.9\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 50\n",
    "\n",
    "# init_screen = env._get_observation()\n",
    "# screen_height, screen_width, _ = init_screen.shape\n",
    "\n",
    "policy_net = DQN().to(device) #DQN(screen_height, screen_width).to(device)\n",
    "target_net = DQN().to(device) #DQN(screen_height, screen_width).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict()) \n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayBuffer(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119bec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c505287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c7a119ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropyMethod(state,\n",
    "                       sample_fn,\n",
    "                      objective_fn,\n",
    "                      update_fn,\n",
    "                      initial_params,\n",
    "                      num_elites,\n",
    "                      num_iterations=1,\n",
    "                      threshold_to_terminate=None):\n",
    "    \n",
    "    updated_params = initial_params\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        samples = sample_fn(**updated_params) # used for dictionaries to give arguments\n",
    "        print(samples)\n",
    "        values = objective_fn(state) #, state)\n",
    "#         print(values)\n",
    "        if isinstance(samples, dict):\n",
    "            sample_order = [i for i, _ in sorted(enumerate(values), key=operator.itemgetter(1))]\n",
    "           \n",
    "            sorted_samples = {k: [v[i] for i in sample_order] for k,v in sample.items()}\n",
    "            \n",
    "            elite_samples = {k:v[-num_elites:] for k, v in sorted_samples.items()}\n",
    "            \n",
    "        else:\n",
    "            print(samples.shape)\n",
    "            sorted_samples = [s for s, _ in sorted(zip(samples,values), key=operator.itemgetter(1))]\n",
    "                \n",
    "            elite_samples = sorted_samples[-num_elites:]\n",
    "                \n",
    "        updated_params = update_fn(elite_samples)\n",
    "            \n",
    "        if ((threshold_to_terminate is not None) and (max(values) > threshold_to_terminate)):\n",
    "            break\n",
    "                \n",
    "    return samples, values, updated_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7ee1b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CEM_policy(object):\n",
    "    def __init__(self,\n",
    "                state, \n",
    "                batch_size=64,\n",
    "                action_size=1):\n",
    "    \n",
    "        self.batch_size = batch_size\n",
    "        self._action_size = action_size\n",
    "\n",
    "        self._action_space = spaces.Box(low=-1, high=1, shape=(3,))\n",
    "        \n",
    "    def sample_action(self, state):\n",
    "            \n",
    "        def objective_fn(state): #, state):\n",
    "            state = state.tile(64,).reshape(64, 11)\n",
    "#             sample = torch.tensor(sample, dtype=torch.float)\n",
    "            q_values = policy_net(state)\n",
    "            return q_values\n",
    "\n",
    "        def sample_fn(mean, std):\n",
    "            return mean + std * np.random.randn(self.batch_size, self._action_size)\n",
    "\n",
    "        def update_fn(elite_samples):\n",
    "            return {'mean': np.mean(elite_samples, axis=0),\n",
    "                   'std': np.std(elite_samples, axis=0, ddof=1)}\n",
    "\n",
    "        global steps_done\n",
    "        mu = np.zeros(1)\n",
    "#         mu[2] = -1\n",
    "        initial_params = {'mean': mu, 'std': .5 * np.ones(1)}\n",
    "        sample, values, final_params = CrossEntropyMethod(state,\n",
    "                                                          sample_fn,\n",
    "                                                         objective_fn,\n",
    "                                                         update_fn,\n",
    "                                                         initial_params,\n",
    "                                                         num_elites=10,\n",
    "                                                         num_iterations=3)\n",
    "        \n",
    "        idx = torch.argmax(values.detach().cpu())\n",
    "        best_cont_actions, best_cont_vals = sample[idx], values[idx]\n",
    "        steps_done += 1\n",
    "        print(best_cont_actions)\n",
    "        return best_cont_actions\n",
    "\n",
    "CEM = CEM_policy(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c08c977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE) \n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach() \n",
    "    \n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch \n",
    "    \n",
    "    criterion = nn.SmoothL1Loss() \n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1b296351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(num_episodes=50, max_episode_length=15):\n",
    "    successes = 0\n",
    "    for i_episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        state = torch.tensor(state, dtype=torch.float)\n",
    "        \n",
    "        for t in range(max_episode_length):\n",
    "            action = CEM.sample_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            if reward == 1:\n",
    "                successes += 1\n",
    "            \n",
    "            state = torch.tensor(next_state, dtype=torch.float)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "    return (successes/50) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "95cecbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Agent(num_episodes=1, max_episode_length=15, save_every=500):\n",
    "    episode_durations = []\n",
    "    eps_history = []\n",
    "    rewards = []\n",
    "    success_rates = []\n",
    "    \n",
    "    for i_episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        state = torch.tensor(state, dtype=torch.float)\n",
    "        \n",
    "        for t in range(max_episode_length):\n",
    "            action = CEM.sample_action(state)\n",
    "            next_state, reward, done, _ = env.step(action.item()) \n",
    "            \n",
    "            reward = torch.tensor([reward], device=device)\n",
    "            next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "            action = torch.tensor(action, dtype=torch.float)\n",
    "            memory.push(state.unsqueeze(0), action.unsqueeze(0), next_state.unsqueeze(0), reward)\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            optimize_model()\n",
    "            \n",
    "            if done:\n",
    "                episode_durations.append(t+1)\n",
    "                break\n",
    "        \n",
    "        rewards.append(reward.item())\n",
    "        \n",
    "        if i_episode % TARGET_UPDATE == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "        if i_episode % save_every == 0:\n",
    "            torch.save(policy_net.state_dict(), 'testing Policy-net DQN.pt')\n",
    "            torch.save(target_net.state_dict(), 'testing Target-net DQN.pt')\n",
    "        \n",
    "        if (i_episode + 1) % 125 == 0:\n",
    "            success_per_1000 = test()\n",
    "            success_rates.append(success_per_1000)\n",
    "            print(\"Episode: \", i_episode + 1, \"/\", num_episodes, success_per_1000)\n",
    "    \n",
    "    final_success = test()\n",
    "    success_rates.append(final_success)\n",
    "    \n",
    "    torch.save(policy_net.state_dict(), 'testing Policy-net DQN.pt')\n",
    "    torch.save(target_net.state_dict(), 'testing Target-net DQN.pt')\n",
    "    print('Complete')\n",
    "    return episode_durations, rewards, success_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d2334c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.07383264e-01  1.07383264e-01  1.07383264e-01  1.07383264e-01\n",
      "   1.07383264e-01  1.07383264e-01  1.07383264e-01  1.07383264e-01\n",
      "   1.07383264e-01  1.07383264e-01  1.07383264e-01]\n",
      " [-9.71306364e-01 -9.71306364e-01 -9.71306364e-01 -9.71306364e-01\n",
      "  -9.71306364e-01 -9.71306364e-01 -9.71306364e-01 -9.71306364e-01\n",
      "  -9.71306364e-01 -9.71306364e-01 -9.71306364e-01]\n",
      " [-4.43585085e-01 -4.43585085e-01 -4.43585085e-01 -4.43585085e-01\n",
      "  -4.43585085e-01 -4.43585085e-01 -4.43585085e-01 -4.43585085e-01\n",
      "  -4.43585085e-01 -4.43585085e-01 -4.43585085e-01]\n",
      " [ 1.50930805e-01  1.50930805e-01  1.50930805e-01  1.50930805e-01\n",
      "   1.50930805e-01  1.50930805e-01  1.50930805e-01  1.50930805e-01\n",
      "   1.50930805e-01  1.50930805e-01  1.50930805e-01]\n",
      " [ 6.04960620e-02  6.04960620e-02  6.04960620e-02  6.04960620e-02\n",
      "   6.04960620e-02  6.04960620e-02  6.04960620e-02  6.04960620e-02\n",
      "   6.04960620e-02  6.04960620e-02  6.04960620e-02]\n",
      " [ 3.76262658e-01  3.76262658e-01  3.76262658e-01  3.76262658e-01\n",
      "   3.76262658e-01  3.76262658e-01  3.76262658e-01  3.76262658e-01\n",
      "   3.76262658e-01  3.76262658e-01  3.76262658e-01]\n",
      " [-4.48141388e-01 -4.48141388e-01 -4.48141388e-01 -4.48141388e-01\n",
      "  -4.48141388e-01 -4.48141388e-01 -4.48141388e-01 -4.48141388e-01\n",
      "  -4.48141388e-01 -4.48141388e-01 -4.48141388e-01]\n",
      " [-2.94515989e-01 -2.94515989e-01 -2.94515989e-01 -2.94515989e-01\n",
      "  -2.94515989e-01 -2.94515989e-01 -2.94515989e-01 -2.94515989e-01\n",
      "  -2.94515989e-01 -2.94515989e-01 -2.94515989e-01]\n",
      " [-1.83028317e-01 -1.83028317e-01 -1.83028317e-01 -1.83028317e-01\n",
      "  -1.83028317e-01 -1.83028317e-01 -1.83028317e-01 -1.83028317e-01\n",
      "  -1.83028317e-01 -1.83028317e-01 -1.83028317e-01]\n",
      " [-4.53911519e-01 -4.53911519e-01 -4.53911519e-01 -4.53911519e-01\n",
      "  -4.53911519e-01 -4.53911519e-01 -4.53911519e-01 -4.53911519e-01\n",
      "  -4.53911519e-01 -4.53911519e-01 -4.53911519e-01]\n",
      " [-1.90532354e-01 -1.90532354e-01 -1.90532354e-01 -1.90532354e-01\n",
      "  -1.90532354e-01 -1.90532354e-01 -1.90532354e-01 -1.90532354e-01\n",
      "  -1.90532354e-01 -1.90532354e-01 -1.90532354e-01]\n",
      " [-6.32945923e-01 -6.32945923e-01 -6.32945923e-01 -6.32945923e-01\n",
      "  -6.32945923e-01 -6.32945923e-01 -6.32945923e-01 -6.32945923e-01\n",
      "  -6.32945923e-01 -6.32945923e-01 -6.32945923e-01]\n",
      " [-5.34340105e-01 -5.34340105e-01 -5.34340105e-01 -5.34340105e-01\n",
      "  -5.34340105e-01 -5.34340105e-01 -5.34340105e-01 -5.34340105e-01\n",
      "  -5.34340105e-01 -5.34340105e-01 -5.34340105e-01]\n",
      " [ 2.94769636e-01  2.94769636e-01  2.94769636e-01  2.94769636e-01\n",
      "   2.94769636e-01  2.94769636e-01  2.94769636e-01  2.94769636e-01\n",
      "   2.94769636e-01  2.94769636e-01  2.94769636e-01]\n",
      " [ 2.36252829e-01  2.36252829e-01  2.36252829e-01  2.36252829e-01\n",
      "   2.36252829e-01  2.36252829e-01  2.36252829e-01  2.36252829e-01\n",
      "   2.36252829e-01  2.36252829e-01  2.36252829e-01]\n",
      " [-4.72280177e-01 -4.72280177e-01 -4.72280177e-01 -4.72280177e-01\n",
      "  -4.72280177e-01 -4.72280177e-01 -4.72280177e-01 -4.72280177e-01\n",
      "  -4.72280177e-01 -4.72280177e-01 -4.72280177e-01]\n",
      " [ 7.92428608e-01  7.92428608e-01  7.92428608e-01  7.92428608e-01\n",
      "   7.92428608e-01  7.92428608e-01  7.92428608e-01  7.92428608e-01\n",
      "   7.92428608e-01  7.92428608e-01  7.92428608e-01]\n",
      " [-6.96430740e-01 -6.96430740e-01 -6.96430740e-01 -6.96430740e-01\n",
      "  -6.96430740e-01 -6.96430740e-01 -6.96430740e-01 -6.96430740e-01\n",
      "  -6.96430740e-01 -6.96430740e-01 -6.96430740e-01]\n",
      " [ 9.81614822e-01  9.81614822e-01  9.81614822e-01  9.81614822e-01\n",
      "   9.81614822e-01  9.81614822e-01  9.81614822e-01  9.81614822e-01\n",
      "   9.81614822e-01  9.81614822e-01  9.81614822e-01]\n",
      " [-4.83250592e-01 -4.83250592e-01 -4.83250592e-01 -4.83250592e-01\n",
      "  -4.83250592e-01 -4.83250592e-01 -4.83250592e-01 -4.83250592e-01\n",
      "  -4.83250592e-01 -4.83250592e-01 -4.83250592e-01]\n",
      " [ 1.95716349e-01  1.95716349e-01  1.95716349e-01  1.95716349e-01\n",
      "   1.95716349e-01  1.95716349e-01  1.95716349e-01  1.95716349e-01\n",
      "   1.95716349e-01  1.95716349e-01  1.95716349e-01]\n",
      " [ 3.07909606e-01  3.07909606e-01  3.07909606e-01  3.07909606e-01\n",
      "   3.07909606e-01  3.07909606e-01  3.07909606e-01  3.07909606e-01\n",
      "   3.07909606e-01  3.07909606e-01  3.07909606e-01]\n",
      " [-1.66752461e-01 -1.66752461e-01 -1.66752461e-01 -1.66752461e-01\n",
      "  -1.66752461e-01 -1.66752461e-01 -1.66752461e-01 -1.66752461e-01\n",
      "  -1.66752461e-01 -1.66752461e-01 -1.66752461e-01]\n",
      " [ 4.89160624e-01  4.89160624e-01  4.89160624e-01  4.89160624e-01\n",
      "   4.89160624e-01  4.89160624e-01  4.89160624e-01  4.89160624e-01\n",
      "   4.89160624e-01  4.89160624e-01  4.89160624e-01]\n",
      " [ 4.42645747e-01  4.42645747e-01  4.42645747e-01  4.42645747e-01\n",
      "   4.42645747e-01  4.42645747e-01  4.42645747e-01  4.42645747e-01\n",
      "   4.42645747e-01  4.42645747e-01  4.42645747e-01]\n",
      " [ 3.12928250e-01  3.12928250e-01  3.12928250e-01  3.12928250e-01\n",
      "   3.12928250e-01  3.12928250e-01  3.12928250e-01  3.12928250e-01\n",
      "   3.12928250e-01  3.12928250e-01  3.12928250e-01]\n",
      " [ 6.54051284e-01  6.54051284e-01  6.54051284e-01  6.54051284e-01\n",
      "   6.54051284e-01  6.54051284e-01  6.54051284e-01  6.54051284e-01\n",
      "   6.54051284e-01  6.54051284e-01  6.54051284e-01]\n",
      " [ 2.95147457e-01  2.95147457e-01  2.95147457e-01  2.95147457e-01\n",
      "   2.95147457e-01  2.95147457e-01  2.95147457e-01  2.95147457e-01\n",
      "   2.95147457e-01  2.95147457e-01  2.95147457e-01]\n",
      " [-6.15697176e-01 -6.15697176e-01 -6.15697176e-01 -6.15697176e-01\n",
      "  -6.15697176e-01 -6.15697176e-01 -6.15697176e-01 -6.15697176e-01\n",
      "  -6.15697176e-01 -6.15697176e-01 -6.15697176e-01]\n",
      " [ 2.27049377e-01  2.27049377e-01  2.27049377e-01  2.27049377e-01\n",
      "   2.27049377e-01  2.27049377e-01  2.27049377e-01  2.27049377e-01\n",
      "   2.27049377e-01  2.27049377e-01  2.27049377e-01]\n",
      " [-6.09638124e-01 -6.09638124e-01 -6.09638124e-01 -6.09638124e-01\n",
      "  -6.09638124e-01 -6.09638124e-01 -6.09638124e-01 -6.09638124e-01\n",
      "  -6.09638124e-01 -6.09638124e-01 -6.09638124e-01]\n",
      " [ 7.94434716e-01  7.94434716e-01  7.94434716e-01  7.94434716e-01\n",
      "   7.94434716e-01  7.94434716e-01  7.94434716e-01  7.94434716e-01\n",
      "   7.94434716e-01  7.94434716e-01  7.94434716e-01]\n",
      " [ 1.23873222e+00  1.23873222e+00  1.23873222e+00  1.23873222e+00\n",
      "   1.23873222e+00  1.23873222e+00  1.23873222e+00  1.23873222e+00\n",
      "   1.23873222e+00  1.23873222e+00  1.23873222e+00]\n",
      " [-3.74863627e-01 -3.74863627e-01 -3.74863627e-01 -3.74863627e-01\n",
      "  -3.74863627e-01 -3.74863627e-01 -3.74863627e-01 -3.74863627e-01\n",
      "  -3.74863627e-01 -3.74863627e-01 -3.74863627e-01]\n",
      " [ 5.30360522e-02  5.30360522e-02  5.30360522e-02  5.30360522e-02\n",
      "   5.30360522e-02  5.30360522e-02  5.30360522e-02  5.30360522e-02\n",
      "   5.30360522e-02  5.30360522e-02  5.30360522e-02]\n",
      " [-1.70427127e-01 -1.70427127e-01 -1.70427127e-01 -1.70427127e-01\n",
      "  -1.70427127e-01 -1.70427127e-01 -1.70427127e-01 -1.70427127e-01\n",
      "  -1.70427127e-01 -1.70427127e-01 -1.70427127e-01]\n",
      " [ 6.81276509e-01  6.81276509e-01  6.81276509e-01  6.81276509e-01\n",
      "   6.81276509e-01  6.81276509e-01  6.81276509e-01  6.81276509e-01\n",
      "   6.81276509e-01  6.81276509e-01  6.81276509e-01]\n",
      " [ 5.34384834e-01  5.34384834e-01  5.34384834e-01  5.34384834e-01\n",
      "   5.34384834e-01  5.34384834e-01  5.34384834e-01  5.34384834e-01\n",
      "   5.34384834e-01  5.34384834e-01  5.34384834e-01]\n",
      " [ 4.39493463e-01  4.39493463e-01  4.39493463e-01  4.39493463e-01\n",
      "   4.39493463e-01  4.39493463e-01  4.39493463e-01  4.39493463e-01\n",
      "   4.39493463e-01  4.39493463e-01  4.39493463e-01]\n",
      " [ 5.86567057e-01  5.86567057e-01  5.86567057e-01  5.86567057e-01\n",
      "   5.86567057e-01  5.86567057e-01  5.86567057e-01  5.86567057e-01\n",
      "   5.86567057e-01  5.86567057e-01  5.86567057e-01]\n",
      " [-8.32646617e-02 -8.32646617e-02 -8.32646617e-02 -8.32646617e-02\n",
      "  -8.32646617e-02 -8.32646617e-02 -8.32646617e-02 -8.32646617e-02\n",
      "  -8.32646617e-02 -8.32646617e-02 -8.32646617e-02]\n",
      " [-5.58233440e-01 -5.58233440e-01 -5.58233440e-01 -5.58233440e-01\n",
      "  -5.58233440e-01 -5.58233440e-01 -5.58233440e-01 -5.58233440e-01\n",
      "  -5.58233440e-01 -5.58233440e-01 -5.58233440e-01]\n",
      " [-4.96990791e-01 -4.96990791e-01 -4.96990791e-01 -4.96990791e-01\n",
      "  -4.96990791e-01 -4.96990791e-01 -4.96990791e-01 -4.96990791e-01\n",
      "  -4.96990791e-01 -4.96990791e-01 -4.96990791e-01]\n",
      " [-7.20561982e-01 -7.20561982e-01 -7.20561982e-01 -7.20561982e-01\n",
      "  -7.20561982e-01 -7.20561982e-01 -7.20561982e-01 -7.20561982e-01\n",
      "  -7.20561982e-01 -7.20561982e-01 -7.20561982e-01]\n",
      " [-1.89165949e-01 -1.89165949e-01 -1.89165949e-01 -1.89165949e-01\n",
      "  -1.89165949e-01 -1.89165949e-01 -1.89165949e-01 -1.89165949e-01\n",
      "  -1.89165949e-01 -1.89165949e-01 -1.89165949e-01]\n",
      " [-3.70446866e-03 -3.70446866e-03 -3.70446866e-03 -3.70446866e-03\n",
      "  -3.70446866e-03 -3.70446866e-03 -3.70446866e-03 -3.70446866e-03\n",
      "  -3.70446866e-03 -3.70446866e-03 -3.70446866e-03]\n",
      " [ 7.13035660e-01  7.13035660e-01  7.13035660e-01  7.13035660e-01\n",
      "   7.13035660e-01  7.13035660e-01  7.13035660e-01  7.13035660e-01\n",
      "   7.13035660e-01  7.13035660e-01  7.13035660e-01]\n",
      " [-2.80599710e-01 -2.80599710e-01 -2.80599710e-01 -2.80599710e-01\n",
      "  -2.80599710e-01 -2.80599710e-01 -2.80599710e-01 -2.80599710e-01\n",
      "  -2.80599710e-01 -2.80599710e-01 -2.80599710e-01]\n",
      " [ 1.91717757e-01  1.91717757e-01  1.91717757e-01  1.91717757e-01\n",
      "   1.91717757e-01  1.91717757e-01  1.91717757e-01  1.91717757e-01\n",
      "   1.91717757e-01  1.91717757e-01  1.91717757e-01]\n",
      " [ 1.25455646e+00  1.25455646e+00  1.25455646e+00  1.25455646e+00\n",
      "   1.25455646e+00  1.25455646e+00  1.25455646e+00  1.25455646e+00\n",
      "   1.25455646e+00  1.25455646e+00  1.25455646e+00]\n",
      " [-7.67492622e-01 -7.67492622e-01 -7.67492622e-01 -7.67492622e-01\n",
      "  -7.67492622e-01 -7.67492622e-01 -7.67492622e-01 -7.67492622e-01\n",
      "  -7.67492622e-01 -7.67492622e-01 -7.67492622e-01]\n",
      " [ 2.35003205e-01  2.35003205e-01  2.35003205e-01  2.35003205e-01\n",
      "   2.35003205e-01  2.35003205e-01  2.35003205e-01  2.35003205e-01\n",
      "   2.35003205e-01  2.35003205e-01  2.35003205e-01]\n",
      " [-7.41203252e-01 -7.41203252e-01 -7.41203252e-01 -7.41203252e-01\n",
      "  -7.41203252e-01 -7.41203252e-01 -7.41203252e-01 -7.41203252e-01\n",
      "  -7.41203252e-01 -7.41203252e-01 -7.41203252e-01]\n",
      " [ 4.55083703e-01  4.55083703e-01  4.55083703e-01  4.55083703e-01\n",
      "   4.55083703e-01  4.55083703e-01  4.55083703e-01  4.55083703e-01\n",
      "   4.55083703e-01  4.55083703e-01  4.55083703e-01]\n",
      " [-1.05454777e-03 -1.05454777e-03 -1.05454777e-03 -1.05454777e-03\n",
      "  -1.05454777e-03 -1.05454777e-03 -1.05454777e-03 -1.05454777e-03\n",
      "  -1.05454777e-03 -1.05454777e-03 -1.05454777e-03]\n",
      " [ 4.27521683e-01  4.27521683e-01  4.27521683e-01  4.27521683e-01\n",
      "   4.27521683e-01  4.27521683e-01  4.27521683e-01  4.27521683e-01\n",
      "   4.27521683e-01  4.27521683e-01  4.27521683e-01]\n",
      " [ 1.90679510e-01  1.90679510e-01  1.90679510e-01  1.90679510e-01\n",
      "   1.90679510e-01  1.90679510e-01  1.90679510e-01  1.90679510e-01\n",
      "   1.90679510e-01  1.90679510e-01  1.90679510e-01]\n",
      " [ 3.67163917e-01  3.67163917e-01  3.67163917e-01  3.67163917e-01\n",
      "   3.67163917e-01  3.67163917e-01  3.67163917e-01  3.67163917e-01\n",
      "   3.67163917e-01  3.67163917e-01  3.67163917e-01]\n",
      " [-5.71735944e-01 -5.71735944e-01 -5.71735944e-01 -5.71735944e-01\n",
      "  -5.71735944e-01 -5.71735944e-01 -5.71735944e-01 -5.71735944e-01\n",
      "  -5.71735944e-01 -5.71735944e-01 -5.71735944e-01]\n",
      " [ 4.23509035e-01  4.23509035e-01  4.23509035e-01  4.23509035e-01\n",
      "   4.23509035e-01  4.23509035e-01  4.23509035e-01  4.23509035e-01\n",
      "   4.23509035e-01  4.23509035e-01  4.23509035e-01]\n",
      " [-8.24499231e-02 -8.24499231e-02 -8.24499231e-02 -8.24499231e-02\n",
      "  -8.24499231e-02 -8.24499231e-02 -8.24499231e-02 -8.24499231e-02\n",
      "  -8.24499231e-02 -8.24499231e-02 -8.24499231e-02]\n",
      " [-5.25010198e-01 -5.25010198e-01 -5.25010198e-01 -5.25010198e-01\n",
      "  -5.25010198e-01 -5.25010198e-01 -5.25010198e-01 -5.25010198e-01\n",
      "  -5.25010198e-01 -5.25010198e-01 -5.25010198e-01]\n",
      " [-6.12282966e-01 -6.12282966e-01 -6.12282966e-01 -6.12282966e-01\n",
      "  -6.12282966e-01 -6.12282966e-01 -6.12282966e-01 -6.12282966e-01\n",
      "  -6.12282966e-01 -6.12282966e-01 -6.12282966e-01]\n",
      " [ 1.12086449e+00  1.12086449e+00  1.12086449e+00  1.12086449e+00\n",
      "   1.12086449e+00  1.12086449e+00  1.12086449e+00  1.12086449e+00\n",
      "   1.12086449e+00  1.12086449e+00  1.12086449e+00]]\n",
      "(64, 11)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-9d0a99758847>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meps_durations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuccess_rates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-108-a5da4e37ee09>\u001b[0m in \u001b[0;36mAgent\u001b[1;34m(num_episodes, max_episode_length, save_every)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_episode_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCEM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-105-6e5de6faea43>\u001b[0m in \u001b[0;36msample_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#         mu[2] = -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0minitial_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         sample, values, final_params = CrossEntropyMethod(state,\n\u001b[0m\u001b[0;32m     32\u001b[0m                                                           \u001b[0msample_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                                                          \u001b[0mobjective_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-104-aa69c0ae7d3e>\u001b[0m in \u001b[0;36mCrossEntropyMethod\u001b[1;34m(state, sample_fn, objective_fn, update_fn, initial_params, num_elites, num_iterations, threshold_to_terminate)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0msorted_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0melite_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnum_elites\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "eps_durations, rewards, success_rates = Agent(num_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "success_percent = (np.array(success_rates)/50) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(success_percent)), success_percent)\n",
    "plt.xlabel('Steps (in 1000 steps)')\n",
    "plt.ylabel('Success')\n",
    "plt.title('Success rate per 1000 steps ')\n",
    "plt.ylim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93812776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982e234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
