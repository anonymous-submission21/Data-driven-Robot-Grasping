{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe03f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7503c3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=C:\\Users\\Kami\\anaconda3\\envs\\robot_grasping\\lib\\site-packages\\pybullet_envs\\bullet\n"
     ]
    }
   ],
   "source": [
    "from pybullet_envs.bullet.kukaGymEnv import KukaGymEnv\n",
    "from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n",
    "import random\n",
    "import os\n",
    "from gym import spaces\n",
    "import time\n",
    "import pybullet as p\n",
    "from pybullet_envs.bullet import kuka\n",
    "import numpy as np\n",
    "import pybullet_data\n",
    "import pdb\n",
    "import distutils.dir_util\n",
    "import glob\n",
    "from pkg_resources import parse_version\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8876f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = KukaDiverseObjectEnv(urdfRoot=pybullet_data.getDataPath(),\n",
    "                           actionRepeat=80,\n",
    "                           isEnableSelfCollision=True,\n",
    "                           renders=True,\n",
    "                           isDiscrete=True,\n",
    "                           maxSteps=15,\n",
    "                           dv=0.06,\n",
    "                           removeHeightHack=False,\n",
    "                           blockRandom=0.,\n",
    "                           cameraRandom=0,\n",
    "                           width=64,\n",
    "                           height=64,\n",
    "                           numObjects=1,\n",
    "                           isTest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4cac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU IS AVAILABLE :D\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU IS AVAILABLE :D') \n",
    "else:  \n",
    "    device = torch.device(\"cpu\") \n",
    "    print('GPU not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741c83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=2, stride=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=2, stride=1)\n",
    "        \n",
    "        self.fn1 = nn.Linear(7*7*32, 32)\n",
    "        self.fn2 = nn.Linear(32, 32)\n",
    "        self.fn3 = nn.Linear(32, outputs) # change outputs to 1 in continuous setting\n",
    "        \n",
    "    def forward(self, x): # x is the observation \n",
    "        x = x.to(device)\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
    "        \n",
    "        x = x.view(-1, 7*7*32) # change width and height in env to 64\n",
    "        x = F.relu(self.fn1(x))\n",
    "        x = F.relu(self.fn2(x))\n",
    "        \n",
    "        return self.fn3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4710aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                       ('state',\n",
    "                       'action',\n",
    "                       'next_state',\n",
    "                       'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "        \n",
    "    def push(self, *args):\n",
    "        \"save a transition\"\n",
    "        self.memory.append(Transition(*args))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994afcda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.9\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 50\n",
    "\n",
    "init_screen = env._get_observation()\n",
    "screen_height, screen_width, _ = init_screen.shape\n",
    "\n",
    "n_actions = 7 #env.action_space # may need to call item or smth\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict()) \n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53076f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net.load_state_dict(torch.load('Policy-net Model.pt'), strict=False) #initial testing\n",
    "target_net.load_state_dict(torch.load('Target-net Model.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61da869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net.load_state_dict(torch.load('Policy-net Model2.pt'), strict=False) # 2nd round of testing\n",
    "target_net.load_state_dict(torch.load('Target-net Model2.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7cbf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net.load_state_dict(torch.load('Policy-net Model final 2.pt'), strict=False) # final round of testing\n",
    "target_net.load_state_dict(torch.load('Target-net Model final 2.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97e43af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dfe8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END # + (EPS_START - EPS_END) * \\\n",
    "#         math.exp(-1. * steps_done / EPS_DECAY) \n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1), eps_threshold\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long), eps_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c99d877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(state):\n",
    "    state = state.transpose((2,0,1))\n",
    "    state = torch.from_numpy(state)\n",
    "    state = state.float()\n",
    "    return state.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e970c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "def plot_durations(): # plotting duration of each episode?\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b1d92e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 20 # max 15 steps per episode\n",
    "success_rate = 0\n",
    "episode_durations = []\n",
    "eps_history = []\n",
    "rewards = []\n",
    "# TD_errors = np.zeros(1000)\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    state = env.reset()\n",
    "    state = get_state(state)\n",
    "\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action, eps = select_action(state)\n",
    "        next_state, reward, done, _ = env.step(action.item()) \n",
    "        \n",
    "        # record any success\n",
    "        if reward == 1:\n",
    "            print('success')\n",
    "            success_rate += 1\n",
    "        \n",
    "        reward = torch.tensor([reward], device=device) # need to change reward from numpy float to tensor and send to device\n",
    "        next_state = get_state(next_state)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        \n",
    "        # record MC error\n",
    "#         TD_error = reward + GAMMA*target_net(next_state).detach() - policy_net(state).detach()\n",
    "#         TD_errors[i_episode] = torch.sum(TD_error).item()\n",
    "        \n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "        \n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "#         optimize_model()\n",
    "        if done: # get duration of episode once episode has terminated\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "            \n",
    "    eps_history.append(eps)\n",
    "    rewards.append(reward)\n",
    "    \n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "#     if i_episode % TARGET_UPDATE == 0:\n",
    "#         target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e704e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# success rate after further training & eps set to eps_end\n",
    "(success_rate/num_episodes)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "496c735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_loop(num_eps=20):\n",
    "    success_rate = 0\n",
    "    episode_durations = []\n",
    "    rewards = []\n",
    "\n",
    "    for i_episode in range(num_eps):\n",
    "        # Initialize the environment and state\n",
    "        state = env.reset()\n",
    "        state = get_state(state)\n",
    "\n",
    "        for t in count():\n",
    "            # Select and perform an action\n",
    "            action, eps = select_action(state)\n",
    "            next_state, reward, done, _ = env.step(action.item()) \n",
    "\n",
    "            # record any success\n",
    "            if reward == 1:\n",
    "                print('success')\n",
    "                success_rate += 1\n",
    "\n",
    "            next_state = get_state(next_state)\n",
    "            state = next_state\n",
    "\n",
    "            if done: \n",
    "                episode_durations.append(t + 1)\n",
    "                break\n",
    "\n",
    "    return success_rate, episode_durations, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bcbe82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "success\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "success_final, eps_final, rewards_final = testing_loop(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbf51ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "success_final, eps_final, rewards_final = testing_loop(10) # final round of testing, 50% success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fdc805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
